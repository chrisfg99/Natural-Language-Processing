{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLE Assessed Coursework 3: Question 2\n",
    "\n",
    "For this assessment, you are expected to complete and submit 4 notebook files.  There is 1 notebook file for each question (to speed up load times).  This is notebook 2 out of 4.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateno=184521 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preliminary imports\n",
    "import sys\n",
    "sys.path.append(r'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources')\n",
    "sys.path.append(r'resources')\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "import random\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import math\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from collections import Counter\n",
    "def normalise(tokenlist):\n",
    "    tokenlist=[token.lower() for token in tokenlist]\n",
    "    tokenlist=[\"NUM\" if token.isdigit() else token for token in tokenlist]\n",
    "    tokenlist=[\"Nth\" if (token.endswith((\"nd\",\"st\",\"th\")) and token[:-2].isdigit()) else token for token in tokenlist]\n",
    "    tokenlist=[\"NUM\" if re.search(\"^[+-]?[0-9]+\\.[0-9]\",token) else token for token in tokenlist]\n",
    "    return tokenlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Distributional Semantics (25 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1113359"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcr = ReutersCorpusReader().finance()\n",
    "rcr.enumerate_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0%\n",
      "Completed 1%\n",
      "Completed 2%\n",
      "Completed 3%\n",
      "Completed 4%\n",
      "Completed 5%\n",
      "Completed 6%\n",
      "Completed 7%\n",
      "Completed 8%\n",
      "Completed 9%\n",
      "Completed 10%\n",
      "Completed 11%\n",
      "Completed 12%\n",
      "Completed 13%\n",
      "Completed 14%\n",
      "Completed 15%\n",
      "Completed 16%\n",
      "Completed 17%\n",
      "Completed 18%\n",
      "Completed 19%\n",
      "Completed 20%\n",
      "Completed 21%\n",
      "Completed 22%\n",
      "Completed 23%\n",
      "Completed 24%\n",
      "Completed 25%\n",
      "Completed 26%\n",
      "Completed 27%\n",
      "Completed 28%\n",
      "Completed 29%\n",
      "Completed 30%\n",
      "Completed 31%\n",
      "Completed 32%\n",
      "Completed 33%\n",
      "Completed 34%\n",
      "Completed 35%\n",
      "Completed 36%\n",
      "Completed 37%\n",
      "Completed 38%\n",
      "Completed 39%\n",
      "Completed 40%\n",
      "Completed 41%\n",
      "Completed 42%\n",
      "Completed 43%\n",
      "Completed 44%\n",
      "Completed 45%\n",
      "Completed 46%\n",
      "Completed 47%\n",
      "Completed 48%\n",
      "Completed 49%\n",
      "Completed 50%\n",
      "Completed 51%\n",
      "Completed 52%\n",
      "Completed 53%\n",
      "Completed 54%\n",
      "Completed 55%\n",
      "Completed 56%\n",
      "Completed 57%\n",
      "Completed 58%\n",
      "Completed 59%\n",
      "Completed 60%\n",
      "Completed 61%\n",
      "Completed 62%\n",
      "Completed 63%\n",
      "Completed 64%\n",
      "Completed 65%\n",
      "Completed 66%\n",
      "Completed 67%\n",
      "Completed 68%\n",
      "Completed 69%\n",
      "Completed 70%\n",
      "Completed 71%\n",
      "Completed 72%\n",
      "Completed 73%\n",
      "Completed 74%\n",
      "Completed 75%\n",
      "Completed 76%\n",
      "Completed 77%\n",
      "Completed 78%\n",
      "Completed 79%\n",
      "Completed 80%\n",
      "Completed 81%\n",
      "Completed 82%\n",
      "Completed 83%\n",
      "Completed 84%\n",
      "Completed 85%\n",
      "Completed 86%\n",
      "Completed 87%\n",
      "Completed 88%\n",
      "Completed 89%\n",
      "Completed 90%\n",
      "Completed 91%\n",
      "Completed 92%\n",
      "Completed 93%\n",
      "Completed 94%\n",
      "Completed 95%\n",
      "Completed 96%\n",
      "Completed 97%\n",
      "Completed 98%\n",
      "Completed 99%\n",
      "Completed 100%\n"
     ]
    }
   ],
   "source": [
    "random.seed(candidateno)  \n",
    "samplesize=2000\n",
    "iterations =100\n",
    "sentences=[]\n",
    "for i in range(0,iterations):\n",
    "    sentences+=[normalise(sent) for sent in rcr.sample_sents(samplesize=samplesize)]\n",
    "    print(\"Completed {}%\".format(i))\n",
    "print(\"Completed 100%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(sentences,window=1):#given the sentences array as generated above and _____\n",
    "    mydict={} #create Dictionary\n",
    "    for sentence in sentences: #takes each sentence from the given sentences array\n",
    "        for i,token in enumerate(sentence): #iterates through every word in a the selected sentence\n",
    "            current=mydict.get(token,{}) #retrieves a set from mydict and applies it to the variable 'current'\n",
    "            features=sentence[max(0,i-window):i]+sentence[i+1:i+window+1] #variable 'features' is created and is assigned\n",
    "                                                                          #the words from a sentence\n",
    "            for feature in features:#iterates through every feature in features\n",
    "                current[feature]=current.get(feature,0)+1 #the selected \"feature\" is then used to get a token and assign it \n",
    "                                                          #to current\n",
    "            mydict[token]=current #the current set is then added to 'mydict' with the key being the current 'token'\n",
    "    return mydict # dictionary 'mydict' is then returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Run** `generate_features(sentences[:5])`.  With reference to the code and the specific examples, **explain** how the output was generated. \\[4 marks\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': {'issuer/type': 1},\n",
       " 'issuer/type': {'amount': 1, 'sale': 1},\n",
       " 'sale': {'issuer/type': 1, 'date': 1},\n",
       " 'date': {'sale': 1},\n",
       " 'many': {'german': 1},\n",
       " 'german': {'many': 1, 'officials': 1},\n",
       " 'officials': {'german': 1, 'now': 1},\n",
       " 'now': {'officials': 1, 'say': 1},\n",
       " 'say': {'now': 1, 'the': 1},\n",
       " 'the': {'say': 1, 'correction': 1, 'that': 1, 'bank': 1},\n",
       " 'correction': {'the': 1, 'is': 1},\n",
       " 'is': {'correction': 1, 'complete': 1},\n",
       " 'complete': {'is': 1, '.': 1},\n",
       " '.': {'complete': 1, 'hold': 1},\n",
       " 'mario': {'angastiniotis': 1},\n",
       " 'angastiniotis': {'mario': 1, ',': 1},\n",
       " ',': {'angastiniotis': 1, 'economist': 2, 'mms': 1},\n",
       " 'economist': {',': 2},\n",
       " 'mms': {',': 1, 'international': 1},\n",
       " 'international': {'mms': 1, ':': 1},\n",
       " ':': {'international': 1, '``': 1},\n",
       " '``': {':': 1, 'it': 1},\n",
       " 'it': {'``': 1, 'means': 1},\n",
       " 'means': {'it': 1, 'that': 1},\n",
       " 'that': {'means': 1, 'the': 1},\n",
       " 'bank': {'the': 1, 'of': 1},\n",
       " 'of': {'bank': 1, 'canada': 1},\n",
       " 'canada': {'of': 1, 'still': 1},\n",
       " 'still': {'canada': 1, 'has': 1},\n",
       " 'has': {'still': 1, 'room': 1},\n",
       " 'room': {'has': 1, 'to': 1},\n",
       " 'to': {'room': 1, 'stay': 1},\n",
       " 'stay': {'to': 1, 'on': 1},\n",
       " 'on': {'stay': 1, 'hold': 1},\n",
       " 'hold': {'on': 1, '.': 1},\n",
       " '--': {'july': 1},\n",
       " 'july': {'--': 1, 'NUM': 1},\n",
       " 'NUM': {'july': 1, 'june': 1},\n",
       " 'june': {'NUM': 1, 'export': 1},\n",
       " 'export': {'june': 1, 'and': 1},\n",
       " 'and': {'export': 1, 'import': 1},\n",
       " 'import': {'and': 1, 'prices': 1},\n",
       " 'prices': {'import': 1, '(': 1},\n",
       " '(': {'prices': 1, 'sf': 1},\n",
       " 'sf': {'(': 1, ')': 1},\n",
       " ')': {'sf': 1}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_features(sentences[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'generate_features' function begins with it being given the sentences array, which was generated in the previous cell and contains a sample of 100 sentences picked using the seed being my candidate number, but only the first 5 sentences of the 100 sentence array. The function is also given the variable 'window' which is assigned the value of 1.\n",
    "After this it initialises a dictionary, 'mydict', before iterating through the five given sentences with a for loop before enumerating each word of the sentence allowing it to be iterated through using its value 'i' and the word 'token'.\n",
    "The function then assigns the variable 'current' with a blank set from 'mydict' with the current word, 'token' being its key along with assigning the variable 'features' with the  a set of two words either side of the current token being at positions 'i-1' and 'i+1' with 'i' being the tokens position.\n",
    "The variable 'features' is then iterated through feature by feature and each feature as a key for that features previous and next tokens allowing all features of a sentence to be put into a single variable as a dictionary. This dictionary can then be put into the dictionary 'mydict' which becomes a dictionary of all of the sentences features. A feature being a tokens that are either side of the token in its sentence, however if a token appears more than once then this means it has multiple features and therefores shall have multiple words following its key in the dictionary. Each feature is also given a counter to show how many times it is a feature of the given word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write code and **find** the 100 most frequently occurring words that\n",
    "* are in your sample; AND\n",
    "* have at least one noun sense according to WordNet\n",
    "\\[ 4 marks\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNouns(sentences):\n",
    "    #initialise noun array\n",
    "    sym={}\n",
    "    nouns=[]\n",
    "    temp=''\n",
    "    #iterate through each word in the sentence and each sentence in the given sentences\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            #add them to nouns array if a noun\n",
    "            if(len(wn.synsets(word,\"n\"))>0):\n",
    "                nouns.append(word)\n",
    "    return nouns\n",
    "\n",
    "nouns= getNouns(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hundredNouns(sentences,n):\n",
    "    #remove all punctuation\n",
    "    #count how often each word appears\n",
    "    c=Counter(n)\n",
    "    #get top 100\n",
    "    topHundred=c.most_common(100)\n",
    "    #return top 100\n",
    "    return (topHundred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 56047),\n",
       " ('a', 49052),\n",
       " ('percent', 17923),\n",
       " ('it', 15516),\n",
       " ('be', 14624),\n",
       " ('pct', 14508),\n",
       " ('at', 13930),\n",
       " ('was', 13406),\n",
       " ('will', 11124),\n",
       " ('he', 11011),\n",
       " ('as', 10887),\n",
       " ('bank', 9319),\n",
       " ('year', 8929),\n",
       " ('million', 8820),\n",
       " ('has', 8583),\n",
       " ('have', 8575),\n",
       " ('may', 8507),\n",
       " ('are', 8485),\n",
       " ('its', 8387),\n",
       " ('government', 8305),\n",
       " ('an', 7949),\n",
       " ('billion', 7128),\n",
       " ('tax', 5776),\n",
       " ('uk', 5693),\n",
       " ('trade', 5554),\n",
       " ('rate', 5430),\n",
       " ('budget', 4993),\n",
       " ('more', 4833),\n",
       " ('growth', 4668),\n",
       " ('last', 4622),\n",
       " ('u.s.', 4447),\n",
       " ('first', 4431),\n",
       " ('central', 4259),\n",
       " ('price', 4082),\n",
       " ('market', 4026),\n",
       " ('june', 3989),\n",
       " ('newsroom', 3986),\n",
       " ('over', 3933),\n",
       " ('or', 3911),\n",
       " ('union', 3833),\n",
       " ('there', 3809),\n",
       " ('inflation', 3773),\n",
       " ('state', 3753),\n",
       " ('bonds', 3682),\n",
       " ('rates', 3479),\n",
       " ('one', 3410),\n",
       " ('minister', 3404),\n",
       " ('i', 3404),\n",
       " ('economy', 3365),\n",
       " ('week', 3357),\n",
       " ('no', 3357),\n",
       " ('can', 3324),\n",
       " ('prices', 3296),\n",
       " ('april', 3259),\n",
       " ('currency', 3220),\n",
       " ('interest', 3138),\n",
       " ('two', 3137),\n",
       " ('finance', 3115),\n",
       " ('deficit', 2947),\n",
       " ('gdp', 2919),\n",
       " ('july', 2745),\n",
       " ('years', 2741),\n",
       " ('time', 2717),\n",
       " ('european', 2692),\n",
       " ('wednesday', 2660),\n",
       " ('tuesday', 2645),\n",
       " ('out', 2576),\n",
       " ('march', 2535),\n",
       " ('thursday', 2527),\n",
       " ('apr', 2477),\n",
       " ('sales', 2446),\n",
       " ('official', 2434),\n",
       " ('who', 2391),\n",
       " ('change', 2385),\n",
       " ('index', 2385),\n",
       " ('policy', 2327),\n",
       " ('rise', 2316),\n",
       " ('due', 2301),\n",
       " ('total', 2295),\n",
       " ('current', 2285),\n",
       " ('issue', 2274),\n",
       " ('mon', 2221),\n",
       " ('fri', 2221),\n",
       " ('three', 2219),\n",
       " ('month', 2218),\n",
       " ('unemployment', 2214),\n",
       " ('investment', 2203),\n",
       " ('public', 2192),\n",
       " ('balance', 2190),\n",
       " ('president', 2139),\n",
       " ('debt', 2139),\n",
       " ('wed', 2135),\n",
       " ('consumer', 2129),\n",
       " ('friday', 2124),\n",
       " ('international', 2114),\n",
       " ('monday', 2092),\n",
       " ('country', 2065),\n",
       " ('do', 2062),\n",
       " ('bond', 2041),\n",
       " ('months', 2041)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hundredNouns(sentences,nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write code to create distributional vector representations of each word in the corpus with a parameter to specify context window size.   \\[5 marks \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorRep(sentences,window):\n",
    "    temp=[]\n",
    "    for tokens in sentences:\n",
    "        for i,word in enumerate(tokens):\n",
    "            temp.append((word,tokens[max(0,i-window):i]+tokens[i+1:i+window+1]))\n",
    "    return temp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector=vectorRep(sentences,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Distrubution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>[increase]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>increase</td>\n",
       "      <td>[the, followed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>followed</td>\n",
       "      <td>[increase, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>[followed, revised]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>revised</td>\n",
       "      <td>[a, NUM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NUM</td>\n",
       "      <td>[revised, percent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>percent</td>\n",
       "      <td>[NUM, drop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drop</td>\n",
       "      <td>[percent, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>[drop, may]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>may</td>\n",
       "      <td>[in, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>[may, when]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>when</td>\n",
       "      <td>[,, starts]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>starts</td>\n",
       "      <td>[when, were]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>were</td>\n",
       "      <td>[starts, running]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>running</td>\n",
       "      <td>[were, at]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>at</td>\n",
       "      <td>[running, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a</td>\n",
       "      <td>[at, NUM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NUM</td>\n",
       "      <td>[a, million]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>million</td>\n",
       "      <td>[NUM, rate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rate</td>\n",
       "      <td>[million, for]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>for</td>\n",
       "      <td>[rate, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>the</td>\n",
       "      <td>[for, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>year</td>\n",
       "      <td>[the, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>[year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jospin</td>\n",
       "      <td>['s]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>'s</td>\n",
       "      <td>[jospin, government]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>government</td>\n",
       "      <td>['s, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>,</td>\n",
       "      <td>[government, in]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>in</td>\n",
       "      <td>[,, line]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>line</td>\n",
       "      <td>[in, with]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292249</th>\n",
       "      <td>republic</td>\n",
       "      <td>[federal, of]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292250</th>\n",
       "      <td>of</td>\n",
       "      <td>[republic, yugoslavia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292251</th>\n",
       "      <td>yugoslavia</td>\n",
       "      <td>[of, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292252</th>\n",
       "      <td>,</td>\n",
       "      <td>[yugoslavia, comprising]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292253</th>\n",
       "      <td>comprising</td>\n",
       "      <td>[,, serbia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292254</th>\n",
       "      <td>serbia</td>\n",
       "      <td>[comprising, and]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292255</th>\n",
       "      <td>and</td>\n",
       "      <td>[serbia, montenegro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292256</th>\n",
       "      <td>montenegro</td>\n",
       "      <td>[and, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292257</th>\n",
       "      <td>.</td>\n",
       "      <td>[montenegro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292258</th>\n",
       "      <td>the</td>\n",
       "      <td>[unions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292259</th>\n",
       "      <td>unions</td>\n",
       "      <td>[the, hailed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292260</th>\n",
       "      <td>hailed</td>\n",
       "      <td>[unions, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292261</th>\n",
       "      <td>the</td>\n",
       "      <td>[hailed, decision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292262</th>\n",
       "      <td>decision</td>\n",
       "      <td>[the, as]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292263</th>\n",
       "      <td>as</td>\n",
       "      <td>[decision, a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292264</th>\n",
       "      <td>a</td>\n",
       "      <td>[as, victory]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292265</th>\n",
       "      <td>victory</td>\n",
       "      <td>[a, ,]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292266</th>\n",
       "      <td>,</td>\n",
       "      <td>[victory, while]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292267</th>\n",
       "      <td>while</td>\n",
       "      <td>[,, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292268</th>\n",
       "      <td>the</td>\n",
       "      <td>[while, newspapers]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292269</th>\n",
       "      <td>newspapers</td>\n",
       "      <td>[the, said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292270</th>\n",
       "      <td>said</td>\n",
       "      <td>[newspapers, they]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292271</th>\n",
       "      <td>they</td>\n",
       "      <td>[said, were]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292272</th>\n",
       "      <td>were</td>\n",
       "      <td>[they, likely]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292273</th>\n",
       "      <td>likely</td>\n",
       "      <td>[were, to]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292274</th>\n",
       "      <td>to</td>\n",
       "      <td>[likely, appeal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292275</th>\n",
       "      <td>appeal</td>\n",
       "      <td>[to, the]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292276</th>\n",
       "      <td>the</td>\n",
       "      <td>[appeal, decision]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292277</th>\n",
       "      <td>decision</td>\n",
       "      <td>[the, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292278</th>\n",
       "      <td>.</td>\n",
       "      <td>[decision]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3292279 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word              Distrubution\n",
       "0               the                [increase]\n",
       "1          increase           [the, followed]\n",
       "2          followed             [increase, a]\n",
       "3                 a       [followed, revised]\n",
       "4           revised                  [a, NUM]\n",
       "5               NUM        [revised, percent]\n",
       "6           percent               [NUM, drop]\n",
       "7              drop             [percent, in]\n",
       "8                in               [drop, may]\n",
       "9               may                   [in, ,]\n",
       "10                ,               [may, when]\n",
       "11             when               [,, starts]\n",
       "12           starts              [when, were]\n",
       "13             were         [starts, running]\n",
       "14          running                [were, at]\n",
       "15               at              [running, a]\n",
       "16                a                 [at, NUM]\n",
       "17              NUM              [a, million]\n",
       "18          million               [NUM, rate]\n",
       "19             rate            [million, for]\n",
       "20              for               [rate, the]\n",
       "21              the               [for, year]\n",
       "22             year                  [the, .]\n",
       "23                .                    [year]\n",
       "24           jospin                      ['s]\n",
       "25               's      [jospin, government]\n",
       "26       government                   ['s, ,]\n",
       "27                ,          [government, in]\n",
       "28               in                 [,, line]\n",
       "29             line                [in, with]\n",
       "...             ...                       ...\n",
       "3292249    republic             [federal, of]\n",
       "3292250          of    [republic, yugoslavia]\n",
       "3292251  yugoslavia                   [of, ,]\n",
       "3292252           ,  [yugoslavia, comprising]\n",
       "3292253  comprising               [,, serbia]\n",
       "3292254      serbia         [comprising, and]\n",
       "3292255         and      [serbia, montenegro]\n",
       "3292256  montenegro                  [and, .]\n",
       "3292257           .              [montenegro]\n",
       "3292258         the                  [unions]\n",
       "3292259      unions             [the, hailed]\n",
       "3292260      hailed             [unions, the]\n",
       "3292261         the        [hailed, decision]\n",
       "3292262    decision                 [the, as]\n",
       "3292263          as             [decision, a]\n",
       "3292264           a             [as, victory]\n",
       "3292265     victory                    [a, ,]\n",
       "3292266           ,          [victory, while]\n",
       "3292267       while                  [,, the]\n",
       "3292268         the       [while, newspapers]\n",
       "3292269  newspapers               [the, said]\n",
       "3292270        said        [newspapers, they]\n",
       "3292271        they              [said, were]\n",
       "3292272        were            [they, likely]\n",
       "3292273      likely                [were, to]\n",
       "3292274          to          [likely, appeal]\n",
       "3292275      appeal                 [to, the]\n",
       "3292276         the        [appeal, decision]\n",
       "3292277    decision                  [the, .]\n",
       "3292278           .                [decision]\n",
       "\n",
       "[3292279 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pd.DataFrame(vector,columns=[\"Word\",\"Distrubution\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Plan and carry out an investigation into the correlation between semantic similarity according to the WordNet path similarity measure and distributional similarity with different context window sizes.  You should make sure that you include a graph of how correlation varies with context window size and that you discuss your results.  \\[12 marks\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

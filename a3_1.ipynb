{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLE Assessed Coursework 3: Question 1\n",
    "\n",
    "For this assessment, you are expected to complete and submit 4 notebook files.  There is 1 notebook file for each question (to speed up load times).  This is notebook 1 out of 4.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateno=184521 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sussex NLTK root directory is resources\n"
     ]
    }
   ],
   "source": [
    "#preliminary imports\n",
    "import sys\n",
    "sys.path.append(r'resources')\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools impor\n",
    "\n",
    "t zip_longest\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sussex_nltk.corpus_readers import AmazonReviewCorpusReader\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Part-of-Speech Tagging (25 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do NOT change the code in this cell.\n",
    "\n",
    "#preparing corpus\n",
    "def display_sent(asent):\n",
    "    headings=[\"token\",\"lower\",\"lemma\",\"pos\",\"NER\"]\n",
    "    info=[]\n",
    "    for t in asent:\n",
    "        info.append([t.text,t.lower_,t.lemma_,t.pos_,t.ent_type_])\n",
    "    return(pd.DataFrame(info,columns=headings))\n",
    "\n",
    "def tag_sent(asent):\n",
    "    tagged=[]\n",
    "    for t in asent:\n",
    "        tagged.append((t.lower_,t.pos_))\n",
    "    return tagged\n",
    "\n",
    "def clean_text(astring):\n",
    "    #replace newlines with space\n",
    "    newstring=re.sub(\"\\n\",\" \",astring)\n",
    "    #remove title and chapter headings\n",
    "    newstring=re.sub(\"\\[[^\\]]*\\]\",\" \",newstring)\n",
    "    newstring=re.sub(\"VOLUME \\S+\",\" \",newstring)\n",
    "    newstring=re.sub(\"CHAPTER \\S+\",\" \",newstring)\n",
    "    newstring=re.sub(\"\\s\\s+\",\" \",newstring)\n",
    "    #return re.sub(\"([^\\.|^ ])  +\",r\"\\1 .  \",newstring).lstrip().rstrip()\n",
    "    return newstring.lstrip().rstrip()\n",
    "\n",
    "def display_tags(sentslist):\n",
    "    taglist={}\n",
    "    for s in sentslist:\n",
    "        for t in s:\n",
    "            form=t.lower_\n",
    "            pos=t.pos_\n",
    "            taglist[pos]=taglist.get(pos,0)+1\n",
    "    print(len(taglist.keys()))\n",
    "    print(taglist)\n",
    "        \n",
    "def get_train_test(sentslist,seed=candidateno):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(sentslist)\n",
    "    testsize=10\n",
    "    train=[tag_sent(s) for s in sentslist[testsize:]]\n",
    "    test=[tag_sent(s) for s in sentslist[:testsize]]\n",
    "    return train,test\n",
    "    \n",
    "alice=clean_text(gutenberg.raw('carroll-alice.txt'))\n",
    "nlp_alice=list(nlp(alice).sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will generate (unique to you) training and test sets of pos-tagged sentences from the novel \"Alice in Wonderland\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "allsents=list(nlp_alice)\n",
    "train,test=get_train_test(allsents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, a class `unigram_tagger` is defined, which will be used in parts a and b of this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "class unigram_tagger():\n",
    "    \n",
    "    def __init__(self,trainingdata=[]):\n",
    "        self.tagcounts={}\n",
    "        self.wordcounts={}\n",
    "        self.tagperwordcounts={}\n",
    "        self.train(trainingdata=trainingdata)\n",
    "        \n",
    "    def train(self,trainingdata):\n",
    "        \n",
    "        for sentence in trainingdata:\n",
    "            for token,tag in sentence:\n",
    "                self.tagcounts[tag]=self.tagcounts.get(tag,0)+1\n",
    "                self.wordcounts[token]=self.wordcounts.get(token,0)+1\n",
    "                current=self.tagperwordcounts.get(token,{})\n",
    "                current[tag]=current.get(tag,0)+1\n",
    "                self.tagperwordcounts[token]=current\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Create an instance of the `unigram_tagger` class which is trained on your training sentences from \"Alice in Wonderland\" (stored in `train`).\n",
    "Explain what is stored, after training, in the three instance variables:\n",
    "* `self.tagcounts`\n",
    "* `self.wordcounts`\n",
    "* `self.tagperwordcounts`\n",
    "\n",
    "You should refer to the code and specific examples from the training data. \\[4 marks \\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tagger= unigram_tagger(train)\n",
    "trained=unigram_tagger.train(Tagger,train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .tagcounts variable counts the total number of occurences that a certain tag that has been applied to words. For example with my training data there are 9222 words tagged as \"VERB\" as well as 2782 tagged as \"ADJ\" aka adjectives. This variable stores the number of tags for many different tags such as pronouns, numbers and punctuation, in total there are 16 different tags that are counted in my data. \n",
    "\n",
    "The .wordcounts variable is very similar to .tagcounts but instead of counting the tags of each word it counts the occurence of each word in the data set, for example \"i\" appears 1066 times but \"footman\" only appears 28 times. This variable does however have some fatal flawws as it counts punctuation such as \"'\" and suffix's such as \"'ll\" which are not words and therefore shouldn't necessarily be counted as such.\n",
    "\n",
    "The .tagperwordcounts variable takes the previous two variables and combines them into one by taking each word and counting how many times each tag is applied to it. For example \"i\" is only tagged with \"PRON\" aka pronoun and this occurs 1066 times but \"no\" is tagged as \"INTJ\", \"DET\" and \"ADV\" with their totals being 40, 126 and 14 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) In the cells below, **extend** the code for the `unigram_tagger` class so that it also has a `tag()` method.  This method should assign the tag, $t$, which maximises the unigram tag probability, $P(t|w)$, for the observed word, $w$.  **Evaluate** the performance of the `unigram_tagger` on your test sentences.  **Discuss** your results. \\[8 marks\\] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "class unigram_tagger():\n",
    "    \n",
    "    def __init__(self,trainingdata=[]):\n",
    "        self.tagcounts={}\n",
    "        self.wordcounts={}\n",
    "        self.tagperwordcounts={}\n",
    "        self.train(trainingdata=trainingdata)\n",
    "        \n",
    "    def train(self,trainingdata):\n",
    "        for sentence in trainingdata:\n",
    "            for token,tag in sentence:\n",
    "                self.tagcounts[tag]=self.tagcounts.get(tag,0)+1\n",
    "                self.wordcounts[token]=self.wordcounts.get(token,0)+1\n",
    "                current=self.tagperwordcounts.get(token,{})\n",
    "                current[tag]=current.get(tag,0)+1\n",
    "                self.tagperwordcounts[token]=current\n",
    "    \n",
    "    def tag(self,data):\n",
    "        words_tagged = []\n",
    "        for sentence in data:\n",
    "            for word in sentence:\n",
    "                if (word[0] in self.tagperwordcounts):\n",
    "                    dist = self.tagperwordcounts[word[0]]\n",
    "                    ordered = sorted(list(dist.items()), key = operator.itemgetter(1), reverse = True)\n",
    "                    words_tagged.append((word[0],ordered[0][0]))\n",
    "                else:\n",
    "                    words_tagged.append((word,'NONE'))\n",
    "        return words_tagged\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('said', 'VERB'), ('alice', 'PROPN'), ('indignantly', 'ADV'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), ('please', 'INTJ'), (',', 'PUNCT'), ((\"ma'am\", 'PROPN'), 'NONE'), (',', 'PUNCT'), ('is', 'AUX'), ('this', 'DET'), ('new', 'ADJ'), (('zealand', 'PROPN'), 'NONE'), ('or', 'CCONJ'), (('australia', 'PROPN'), 'NONE'), ('?', 'PUNCT'), (\"'\", 'PUNCT'), ('*', 'PUNCT'), ('here', 'ADV'), ('the', 'DET'), ('dormouse', 'PROPN'), ('shook', 'VERB'), ('itself', 'PRON'), (',', 'PUNCT'), ('and', 'CCONJ'), ('began', 'VERB'), ('singing', 'VERB'), ('in', 'ADP'), ('its', 'DET'), ('sleep', 'NOUN'), (\"'\", 'PUNCT'), ('twinkle', 'PROPN'), (',', 'PUNCT'), ('twinkle', 'PROPN'), (',', 'PUNCT'), ('twinkle', 'PROPN'), (',', 'PUNCT'), ('twinkle--', 'PROPN'), (\"'\", 'PUNCT'), ('and', 'CCONJ'), ('went', 'VERB'), ('on', 'ADP'), ('so', 'ADV'), ('long', 'ADJ'), ('that', 'DET'), ('they', 'PRON'), ('had', 'AUX'), ('to', 'PART'), ('pinch', 'VERB'), ('it', 'PRON'), ('to', 'PART'), ('make', 'VERB'), ('it', 'PRON'), ('stop', 'VERB'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), ('the', 'DET'), ('soldiers', 'NOUN'), ('were', 'AUX'), ('silent', 'ADJ'), (',', 'PUNCT'), ('and', 'CCONJ'), ('looked', 'VERB'), ('at', 'ADP'), ('alice', 'PROPN'), (',', 'PUNCT'), ('as', 'SCONJ'), ('the', 'DET'), ('question', 'NOUN'), ('was', 'AUX'), (('evidently', 'ADV'), 'NONE'), ('meant', 'VERB'), ('for', 'ADP'), ('her', 'DET'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), ('pat', 'PROPN'), ('!', 'PUNCT'), ('there', 'PRON'), ('is', 'AUX'), (\"n't\", 'PART'), ('any', 'DET'), (',', 'PUNCT'), (\"'\", 'PUNCT'), ('said', 'VERB'), ('the', 'DET'), ('march', 'PROPN'), ('hare', 'PROPN'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), (('soles', 'NOUN'), 'NONE'), ('and', 'CCONJ'), (('eels', 'NOUN'), 'NONE'), (',', 'PUNCT'), ('of', 'ADP'), ('course', 'NOUN'), (',', 'PUNCT'), (\"'\", 'PUNCT'), ('the', 'DET'), ('gryphon', 'PROPN'), ('replied', 'VERB'), ('rather', 'ADV'), ('impatiently', 'ADV'), (':', 'PUNCT'), (\"'\", 'PUNCT'), ('any', 'DET'), (('shrimp', 'NOUN'), 'NONE'), ('could', 'VERB'), ('have', 'AUX'), ('told', 'VERB'), ('you', 'PRON'), ('that', 'DET'), ('.', 'PUNCT'), (\"'\", 'PUNCT'), (\"'\", 'PUNCT'), (\"'\", 'PUNCT'), ('always', 'ADV'), ('lay', 'VERB'), ('the', 'DET'), (('blame', 'NOUN'), 'NONE'), ('on', 'ADP'), ('others', 'NOUN'), ('!', 'PUNCT'), (\"'\", 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "tagger= unigram_tagger(train)\n",
    "tagged=tagger.tag(test)\n",
    "print(tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My trained tagger is very good at tagging the test data correctly however there are one words which could not be tagged as they were not in the training data. Out of the 60 entries there are only 8 which could not be tagged by the tagger and were given the tag of 'NONE', these being blame, shrimp, eels, soles, evdently, Australia, Zealand and ma'am. The majority of these are nouns with only one being an adverb, this makes sense as nouns are context specific and as Alice in Wonderland has nothing to do with Australia or New Zealand there will be no way for the tagger to know what to tag them.\n",
    "\n",
    "Another error that occured was with 'twinkle' which is classified as a Proper Noun although it is more commonly associated with being a verb than a noun this error also also occurs with the verb sleep which can be seen as a \"NOUN\" but is more commonly seen as a \"VERB\". One of these cases of 'twinkle' also has the punctuation of '--' attached to the end which should've been split and tagged appropriately as a \"PUNCT\", punctuation.  \n",
    "\n",
    "Other than these listed errors and non-tagables the tagger performed as expected giving it a 82% success rate and therefore making it very successful. The main way to improve this would be to widen the training data to be less focused on one thing aka Alice in Wonderland and allow it to be able to process more nouns with more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do not change the code in this cell\n",
    "class hmm_tagger():\n",
    "    \n",
    "    def __init__(self,trainingdata=[]):\n",
    "        \n",
    "        self.emissions={}\n",
    "        self.transitions={}\n",
    "        self.train(trainingdata=trainingdata)\n",
    "        \n",
    "    def train(self,trainingdata):\n",
    "        \n",
    "        for sentence in trainingdata:\n",
    "            previous=\"START\"\n",
    "            for token,tag in sentence:\n",
    "                \n",
    "                current=self.emissions.get(tag,{})\n",
    "                current[token]=current.get(token,0)+1\n",
    "                self.emissions[tag]=current\n",
    "                bigram=self.transitions.get(previous,{})\n",
    "                bigram[tag]=bigram.get(tag,0)+1\n",
    "                self.transitions[previous]=bigram\n",
    "                previous=tag\n",
    "                \n",
    "        self.emissions={tag:{token:freq/sum(countdict.values()) for (token,freq) in countdict.items()}for (tag,countdict) in self.emissions.items()}\n",
    "        self.transitions={tag:{token:freq/sum(countdict.values()) for (token,freq) in countdict.items()}for (tag,countdict) in self.transitions.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) **Create** an instance of the `hmm_tagger` class which is trained on your training sentences from \"Alice in Wonderland\" (stored in `train`).  With reference to your testing sentences (stored in `test`), **explain**\n",
    "* how to calculate the probability of an observed sequence of words for a given sequence of tags: $$P(w_1^n|t_1^n)$$\n",
    "* how to calculate the probablity of a possible sequence of tags for a given sequence of words: $$P(t_1^n|w_1^n)$$\n",
    "\n",
    "\\[6 marks\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm=hmm_tagger(train)\n",
    "trained_hmm=hmm.train(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probabilities of an observed sequence of words the emission of each word must be calculated per tag, this is done by iterating through each word and its tag in the given list and counting them as such, in this case the list would be 'test'. The number of times a word is with a particular tag is then divided by the total number of times a word appears overall giving the probability that a word will be of a particular tag. This is then returned as a dictionary of a dictionary with the key of the first dictionary being the given tag, the key of the second being the word and its value being the probability that the word is of that particular tag. \n",
    "In the example of test, with the word 'said' there will be a probability of 1 of it being tagged with 'verb' as said appears twice and both times it is a 'verb'. Using these probabilities it is then possible to predict the probability of a sequence of words such as 'Alice said that'. To do so we look at what each word would need to be tagged to get a the sequence shown, being Proper Noun, Verb and Determiner, and then find the probability that each word would be tagged with the needed tag and multiply them together. This will give the final probability of the sequence occuring being 0.2656776803776148 * 0.09867707655606085 * 0.04755205402363533 giving a 0.0012466340703557 probability of this sequence occuring."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the probability of a possible sequence of tags you must use both emission and transition probabilities by applying Bayes Law. To do this you must get the given sequence of words's tags, so using our previous example of 'alice said that' would give us Proper Noun, Verb and Determiner. Using these values we can then get the transition probabilities for the tags and apply them to Bayes Law to get the final probability of the sequence.\n",
    "To get the transition probabilities we must get each tag and count the occurences of each of its previous tags, once we have these values we take them and apply them to Bayes Rule e.g. ùë°¬†ÃÇ_1^ùëõ=argmax‚î¨(ùë°_1^ùëõ )‚Å°(ùëÉ(ùë§_1^ùëõ‚îÇùë°_1^ùëõ )ùëÉ(ùë°_1^ùëõ) for each word and tag combination. This gives us the equation (0.0615229*0.265677) * (0.03979*0.098677) * (0.0351914*0.047552) giving us the final probability of 1.073954707625416e-7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Using one of your `test` sentences as an example, **explain** how the Viterbi algorithm can be used to find the most likely tag sequence.  You do not need to write code for this question but should explain the calculations that need to be made at each step.  **Comment** on whether the sequence found by the Viterbi algorithm is correct for your chosen test sentence.  **Discuss** why using the Viterbi algorithm is better than the brute-force approach of enumerating and testing all tag sequence possibilities.\\[7 marks\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Viterbi algorithm is a simple algorithm that is utilised to find the best possible path/solution for a problem by starting with the second item of a sequence and working out the optimal value before it, before moving onto the following items in the sequence. \n",
    "\n",
    "For example, we may can take a sentence from 'test' such as 'said alice indignantly', using this we can look at what would be the most likely tag to proceed each of these and therefore construct the most likely tag sequence to go from one to the each other. For this example the three tags that'll be considered will be Verb, ProperNoun and Adjective as they're the three that make up the sentence. Their probabilities for starting the sentence are V:0.114, PN:0.062 and A:0.007 and their probabilities for being assigned to 'Said' are V:0.0987, PN: 0.0007 and A:0. Multiplying these values to gether gives us the first values for this problem being 0.0113 for it being Verb and 0.0004 for it being ProperNoun and 0 for it being an Adjective. Taking this into account means that we will take verb as the starting point and move on to Alice's probabilities of being assigned Verb, ProperNoun and Adjective being V:0, PN:0.266 and A:0. The next stage is to go through all nine possibilities of which tag is most likely to proceed each tag and multiply this value by the probability of the tag being assigned to the word. Using this we can then determine the most likey tag to be assigned to 'Alice'. After these calculations the best method is a ProperNoun being assigned to 'Alice' following Verb that was assigned to 'said'. This process then continues for 'indignantly' and then for the end.\n",
    "\n",
    "After all this the optimal solution is unsuprisingly Verb, ProperNoun, Adjective with a probability of 4.2824e-9 of this sequence occuring.\n",
    "\n",
    "This method is better than brute forcing methods as you don't have to consider everysingle possibility as if you come across a tag that has 0 probability of being assigned to a word then that is three routes that don't have to be considered, in the case of my example. This therefore lowers the running the time of the algorithm and makes its execution much more efficent especially when you don't have to test each combination to check whether it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

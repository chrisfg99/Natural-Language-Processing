{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLE Assessed Coursework 3: Question 4\n",
    "\n",
    "For this assessment, you are expected to complete and submit 4 notebook files.  There is 1 notebook file for each question (to speed up load times).  This is notebook 4 out of 4.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Question Answering (25 marks)\n",
    "Imagine that you have access to a database containing English-language newspaper and magazine articles for the last 50 years. **Describe in detail** how you would go about building a question-answering system to answer questions about historical events including:\n",
    "* Who was the leader of the National Union of Miners during the miners' strikes of the 1980s?\n",
    "* In which years has the football World Cup been held in France?\n",
    "* Where did Princess Diana die?\n",
    "\n",
    "You are not expected to write any code for this question.  You should, however, describe the challenges and the strategies your system will employ to attempt to overcome them.\n",
    "\n",
    "As no code is expected, you can, if you wish, submit a pdf rather than a notebook file for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to go through the question collecting the tag for each word and storing them into a dictionary which is then filtered to leave the questions proper nouns, nouns, verbs, adverbs and numbers, if there are any, which will be needed to get the answer to the question. \n",
    "\n",
    "The adverbs synsets are then collected, for example 'where' would have synsets such as 'location' which will be useful for collecting the final answer for the question, this is as adverbs are important for determining the output of the question. This can be seen in the first example question with 'who' which will have senses for \"Person\" and will therefore define that a Proper Noun with the sense 'Person' is needed.\n",
    "\n",
    "However, before the articles can be looked through for words with these sense the newspapers and magazine articles must be filtered down to be more specific and question related articles. To do so the Proper Nouns collected from the question earlier are used to get only articles containing those Proper Nouns. In terms of the Princess Diana example this means only articles containing the proper noun 'Diana' will now appear in our sample of articles which shall reduce the number of articles to be checked by a lot but not by enough to properly answer the question yet.\n",
    "\n",
    "This is as the sample can be reduced further by restriction via the any other Proper Nouns and if not then Nouns, such as 'Princess' meaning, in the example, the sample now only contains articles about 'Diana' and 'Princess'. This means it is likely we have every article, and more importantly only these articles, about Princess Diana in our sample but this still needs to be made more specific to the context of the question. This is done by reducing the articles down again but this time by restricting them by any verbs and numbers, in this case being the verb 'die' and therefore gives us a sample of articles about the death of Princess Diana. If restricting the sample with a verb leads to no results we can gather the most common symonyms of the word and try these instead, though if these also return no results then the word shall just be skipped. The remaining articles can then be looked through for commonly occuring Proper Nouns or numbers, question dependent, that aren't any of the Proper Nouns from the question and store them locally in an array where the Nouns have their senses collected.\n",
    "\n",
    "Using the collected adverbs from the question, we can then work out what exactly we want from the samples by collection their senses, for example we know we need a location for the Princess Diana question due to the adverb 'where' which has a sense of 'Location'. This means the most common Proper Noun with the sense 'Location' is likely to be our answer, to get this answer we therfore need to look at the most common nouns in our array with the sense location. As it is not possible that the most common word will always be our answer the top 5 words shall be returned in descending order with the most common being the first. This would give the user the ability to assess outputed information and see what the most likely answer is. For example with the Princess Diana example the first word maybe \"Tunnel\" which could indeed be considered a correct answer but the second and third words could be \"Paris\" and \"France\". Using this it is possible to decypher that Princess Diana died in a Tunnel in Paris, France which is indeed the correct answer.\n",
    "\n",
    "This approach will not always work for every single question though as it is not always the case that a noun will be the answer, this can be seen with the second example question where multiple numbers must be returned being the years that the world cup is hosted. Due to this the algorithm will have to be changed slightly to account for the question using which instead of an adverb, this means that we will look at the next word in the setence and gather its senses and use these to determine what too look for as an answer. In this case it gives us year which will have a sense of \"Number\" and will there fore tell us that we need to look for a number. Going through the same process as before we will be left with a small sample of articles relating to the \"World\" \"Cup\" and \"Football\" in  \"France\". At this point instead of looking through for nouns and putting them in an array we shall look through for the most common numbers and list these in descending order of appearances and return to the user.\n",
    "\n",
    "After all of this the final steps for my algoritm are:\n",
    "\n",
    "1.Collect Words and their tags\n",
    "\n",
    "2.Filter list to just proper nouns, nouns, verbs, adverbs and numbers\n",
    "\n",
    "3.Check adverb's sense to see sense of answer\n",
    "\n",
    "3a.In absence of adverb check for \"which\" and take sense of noun after it\n",
    "\n",
    "4.Restrict sample size by Proper Nouns then Nouns then Verbs and then finally by Numbers\n",
    "\n",
    "5.If a word or number reduces sample to zero try symonyms or skip the word\n",
    "\n",
    "6.Collect common Proper Nouns and Nouns or Numbers and put them in an array\n",
    "\n",
    "6a.Restrict array to only contain words with the sense collected in step 3 unless looking for a number\n",
    "\n",
    "8.List remaining words/number in descending order of occurences\n",
    "\n",
    "Another possible approach to this would be to break the documents themselves down into paragraphs and use the collected proper nouns, nouns, verbs, adverbs and numbers to then search through them. This would reduce the size of the sample even further staright away and would save having to scan through unnecessary material. However this method poses the risk of removing paragraphs with valuable data. For example the nouns \"princess\" and \"diana\" maybe referenced in one paragraph but details of her death my be mentioned in the next paragraph which has now been omitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
